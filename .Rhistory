}
clean_list <- function(list_to_clean) {
lapply(list_to_clean, clean_one)
}
get_page_articles(1)
library(rvest)
url <- "https://www.bankier.pl/wiadomosc/"
page <- read_html(url)
nodes <- html_nodes(page, '.entry-title')
titles <- html_text(nodes)
titles[[1]]
# type from : date, title, description
mapping <- list(date = '.entry-date',
title = '.entry-title',
decription = 'p'
)
extract_element <- function(index, type)
{
mapping <- list(date = '.entry-date',
title = '.entry-title',
description = 'p',
content = '.entry-content')
# type from : date, title, description
url <- "https://www.bankier.pl/wiadomosc/"
url <- paste0(url, index)
page <- read_html(url)
nodes <- html_nodes(page, mapping[[type]])
clean_list(html_text(nodes))
}
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descritpions <- extract_element(index, "description")
articles <- as.list(numeric(length = length(dates)))
for (i in seq(length(dates)))
{
articles[i] <- list(date = dates[i],
title = titles[i],
description = descriptions[i]
)
}
}
extract_informations <- function(n_pages) {
articles <- as.list(numeric(length = n_pages))
for (i in seq(n_pages)) {
articles[i] <- get_page_articles(i)
}
unlist(articles, recursive = TRUE)
}
clean_one <- function(string) {
parts <- unlist(strsplit(string, c(" ", "\n")))
parts <- parts[(parts != "") & (parts != "\n")]
paste0(parts, collapse = " ")
}
clean_list <- function(list_to_clean) {
lapply(list_to_clean, clean_one)
}
get_page_articles(1)
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
articles <- as.list(numeric(length = length(dates)))
for (i in seq(length(dates)))
{
articles[i] <- list(date = dates[i],
title = titles[i],
description = descriptions[i]
)
}
}
get_page_articles(1)
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
articles <- list()
for (i in seq(length(dates)))
{
articles[i] <- list(date = dates[i],
title = titles[i],
description = descriptions[i]
)
}
}
get_page_articles(1)
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
articles <- as.list(numeric(length = length(dates)))
for (i in seq(length(dates)))
{
articles[i] <- list(date = dates[i],
title = titles[i],
description = descriptions[i]
)
}
}
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
articles <- as.list(numeric(length = length(dates)))
for (i in seq(length(dates)))
{
articles[i] <- list(date = dates[i],
title = titles[i],
description = descriptions[i]
)
}
articles
}
get_page_articles(1)
extract_element(1, "date")
extract_element(1, "title")
clean_one <- function(string) {
parts <- unlist(strsplit(string, c(" ", "\n")))
parts <- parts[(parts != "") & (parts != "\n")]
paste0(parts, collapse = " ")
}
clean_list <- function(list_to_clean) {
lapply(list_to_clean, clean_one)
}
extract_element <- function(index, type)
{
mapping <- list(date = '.entry-date',
title = '.entry-title',
description = 'p',
content = '.entry-content')
# type from : date, title, description
url <- "https://www.bankier.pl/wiadomosc/"
url <- paste0(url, index)
page <- read_html(url)
nodes <- html_nodes(page, mapping[[type]])
clean_list(html_text(nodes))
}
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
articles <- as.list(numeric(length = length(dates)))
for (i in seq(length(dates)))
{
articles[i] <- list(date = dates[i],
title = titles[i],
description = descriptions[i]
)
}
articles
}
extract_informations <- function(n_pages) {
articles <- as.list(numeric(length = n_pages))
for (i in seq(n_pages)) {
articles[i] <- get_page_articles(i)
}
unlist(articles, recursive = TRUE)
}
extract_element(1, "title")
l <- extract_element(1, "title")
clean_list(l)
clean_one <- function(string) {
parts <- unlist(strsplit(string, c(" ", "\n")))
parts <- parts[(parts != "") & (parts != "\n")]
paste0(parts, collapse = " ")
}
l[[1]]
l <- l[[1]]
clean_one(l)
strsplit(l, c(" ", "\n"))
strsplit(l, c("\n"))
clean_one <- function(string) {
parts <- unlist(strsplit(string, c(" ")))
parts <- parts[(parts != "") & (parts != "\n")]
string <- paste0(parts, collapse = " ")
parts <- unlist(strsplit(string, c("\n")))
parts <- parts[(parts != "") & (parts != "\n")]
paste0(parts, collapse = " ")
}
l <- l[[1]]
clean_one(l)
strsplit(l, c("\n"))
library(rvest)
url <- "https://www.bankier.pl/wiadomosc/"
page <- read_html(url)
nodes <- html_nodes(page, '.entry-title')
titles <- html_text(nodes)
titles[[1]]
# type from : date, title, description
mapping <- list(date = '.entry-date',
title = '.entry-title',
decription = 'p'
)
extract_element <- function(index, type)
{
mapping <- list(date = '.entry-date',
title = '.entry-title',
description = 'p',
content = '.entry-content')
# type from : date, title, description
url <- "https://www.bankier.pl/wiadomosc/"
url <- paste0(url, index)
page <- read_html(url)
nodes <- html_nodes(page, mapping[[type]])
clean_list(html_text(nodes))
}
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
articles <- as.list(numeric(length = length(dates)))
for (i in seq(length(dates)))
{
articles[i] <- list(date = dates[i],
title = titles[i],
description = descriptions[i]
)
}
articles
}
extract_informations <- function(n_pages) {
articles <- as.list(numeric(length = n_pages))
for (i in seq(n_pages)) {
articles[i] <- get_page_articles(i)
}
unlist(articles, recursive = TRUE)
}
clean_one <- function(string) {
parts <- unlist(strsplit(string, c(" ")))
parts <- parts[(parts != "") & (parts != "\n")]
string <- paste0(parts, collapse = " ")
parts <- unlist(strsplit(string, c("\n")))
parts <- parts[(parts != "") & (parts != "\n")]
paste0(parts, collapse = " ")
}
clean_list <- function(list_to_clean) {
lapply(list_to_clean, clean_one)
}
extract_element(1, "title")
extract_element(1, "description")
get_page_articles(1)
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
articles <- list()
for (i in seq(length(dates)))
{
articles <- c(articles, list(date = dates[i],
title = titles[i],
description = descriptions[i]
))
}
articles
}
get_page_articles(1)
a1 <- get_page_articles(1)
a1$date
a1$title
a1
}
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
lapply(seq(length(dates)), function(i) { list(dates[i], titles[i], descriptions[i])})
}
a1 <- get_page_articles(1)
a1
get_page_articles <- function(index) {
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
lapply(seq(length(dates)), function(i) { c(date = dates[i], title = titles[i],
description = descriptions[i])})
}
a1 <- get_page_articles(1)
a1
library(stringi)
library(stringr)
?stringr::str_locate
str_locate(fruit, "a")
str_extract(fruit, "a")
str_locate("Kacper", "a")
?stringr::str_detect
str_detect("Kacper", "a")
str_detect("Kacper", "z")
TRUE | FALSE
TRUE | TRUE
filter <- function(word, article_list, description = TRUE, title = TRUE) {
flags <- as.list(numeric(length = length(article_list)))
i <- 1
for (article in article_list) {
flag1 <- stringr::str_detect(article[["title"]], word)
flag2 <- stringr::str_detect(article[["description"]], word)
flag[i] <- flag1 | flag2
i <- i + 1
}
}
l <- extract_informations(10)
l
get_page_articles(1)
extract_informations <- function(n_pages) {
articles <- list()
for (i in seq(n_pages)) {
articles <- c(articles, get_page_articles(i))
}
unlist(articles, recursive = TRUE)
}
l <- extract_informations(10)
l
extract_informations <- function(n_pages) {
articles <- list()
for (i in seq(n_pages)) {
articles <- c(articles, get_page_articles(i))
}
unlist(articles, recursive = FALSE)
}
l <- extract_informations(10)
l
l$date
extract_informations <- function(n_pages) {
articles <- list()
for (i in seq(n_pages)) {
articles <- c(articles, get_page_articles(i))
}
#unlist(articles, recursive = FALSE)
}
l <- extract_informations(10)
l
extract_informations <- function(n_pages) {
articles <- list()
for (i in seq(n_pages)) {
articles <- c(articles, get_page_articles(i))
}
#unlist(articles, recursive = FALSE)
articles
}
l <- extract_informations(10)
l
filter("brexit", l)
filter <- function(word, article_list, description = TRUE, title = TRUE) {
flags <- as.list(numeric(length = length(article_list)))
i <- 1
for (article in article_list) {
flag1 <- stringr::str_detect(article[["title"]], word)
flag2 <- stringr::str_detect(article[["description"]], word)
flags[i] <- flag1 | flag2
i <- i + 1
}
}
filter("brexit", l)
stringr::str_detect("absadwdasda", "Sadaw")
filter <- function(word, article_list, description = TRUE, title = TRUE) {
flags <- as.list(numeric(length = length(article_list)))
i <- 1
for (article in article_list) {
browser()
flag1 <- stringr::str_detect(article[["title"]], word)
flag2 <- stringr::str_detect(article[["description"]], word)
flags[i] <- flag1 | flag2
i <- i + 1
}
}
filter("brexit", l)
c
filter("brexit", l)
filter("brexit", l)c
filter("brexit", l)
article[["title"]]
article[["description"]]
article[["data"]]
get_page_articles <- function(index) {
browser()
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
lapply(seq(length(dates)), function(i) { c(date = dates[i], title = titles[i],
description = descriptions[i])})
}
get_page_articles(1)
library(rvest)
extract_element <- function(index, type)
{
mapping <- list(date = '.entry-date',
title = '.entry-title',
description = 'p',
content = '.entry-content')
# type from : date, title, description
url <- "https://www.bankier.pl/wiadomosc/"
url <- paste0(url, index)
page <- read_html(url)
nodes <- html_nodes(page, mapping[[type]])
clean_list(html_text(nodes))
}
get_page_articles <- function(index) {
browser()
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
lapply(seq(length(dates)), function(i) { c(date = dates[i], title = titles[i],
description = descriptions[i])})
}
extract_informations <- function(n_pages) {
articles <- list()
for (i in seq(n_pages)) {
articles <- c(articles, get_page_articles(i))
}
#unlist(articles, recursive = FALSE)
articles
}
clean_one <- function(string) {
parts <- unlist(strsplit(string, c(" ")))
parts <- parts[(parts != "") & (parts != "\n")]
string <- paste0(parts, collapse = " ")
parts <- unlist(strsplit(string, c("\n")))
parts <- parts[(parts != "") & (parts != "\n")]
paste0(parts, collapse = " ")
}
clean_list <- function(list_to_clean) {
lapply(list_to_clean, clean_one)
}
filter <- function(word, article_list, description = TRUE, title = TRUE) {
flags <- as.list(numeric(length = length(article_list)))
i <- 1
for (article in article_list) {
browser()
flag1 <- stringr::str_detect(article[["title"]], word)
flag2 <- stringr::str_detect(article[["description"]], word)
flags[i] <- flag1 | flag2
i <- i + 1
}
}
#l <- extract_informations(10)
#filter("brexit", l)
l <- extract_informations(10)
get_page_articles <- function(index) {
#browser()
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
lapply(seq(length(dates)), function(i) { c(date = dates[i], title = titles[i],
description = descriptions[i])})
}
filter <- function(word, article_list, description = TRUE, title = TRUE) {
flags <- as.list(numeric(length = length(article_list)))
i <- 1
for (article in article_list) {
#browser()
flag1 <- stringr::str_detect(article[["title"]], word)
flag2 <- stringr::str_detect(article[["description"]], word)
flags[i] <- flag1 | flag2
i <- i + 1
}
}
l <- extract_informations(10)
filter("brexit", l)
rm(list = ls())
library(rvest)
extract_element <- function(index, type)
{
mapping <- list(date = '.entry-date',
title = '.entry-title',
description = 'p',
content = '.entry-content')
# type from : date, title, description
url <- "https://www.bankier.pl/wiadomosc/"
url <- paste0(url, index)
page <- read_html(url)
nodes <- html_nodes(page, mapping[[type]])
clean_list(html_text(nodes))
}
get_page_articles <- function(index) {
#browser()
dates <- extract_element(index, "date")
titles <- extract_element(index, "title")
descriptions <- extract_element(index, "description")
lapply(seq(length(dates)), function(i) { c(date = dates[i], title = titles[i],
description = descriptions[i])})
}
extract_informations <- function(n_pages) {
articles <- list()
for (i in seq(n_pages)) {
articles <- c(articles, get_page_articles(i))
}
#unlist(articles, recursive = FALSE)
articles
}
clean_one <- function(string) {
parts <- unlist(strsplit(string, c(" ")))
parts <- parts[(parts != "") & (parts != "\n")]
string <- paste0(parts, collapse = " ")
parts <- unlist(strsplit(string, c("\n")))
parts <- parts[(parts != "") & (parts != "\n")]
paste0(parts, collapse = " ")
}
clean_list <- function(list_to_clean) {
lapply(list_to_clean, clean_one)
}
filter <- function(word, article_list, description = TRUE, title = TRUE) {
flags <- as.list(numeric(length = length(article_list)))
i <- 1
for (article in article_list) {
#browser()
flag1 <- stringr::str_detect(article[["title"]], word)
flag2 <- stringr::str_detect(article[["description"]], word)
flags[i] <- flag1 | flag2
i <- i + 1
}
}
l <- extract_informations(10)
filter("brexit", l)
